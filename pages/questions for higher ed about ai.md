- ---
  created: 2025-09-11T08:51:05
  source: https://www.theatlantic.com/culture/archive/2025/09/ai-colleges-universities-solution/684160/
  author: Tyler Austin Harper
  ---
- # The Question All Colleges Should Ask Themselves About AI
  
  Clipped from: https://www.theatlantic.com/culture/archive/2025/09/ai-colleges-universities-solution/684160/
- # The Question All Colleges Should Ask Themselves About AI
  
  How far are they willing to go to limit its harms?
  
  ![Photo-illustration of a desk protected by a castle and drawbridge](https://cdn.theatlantic.com/thumbor/nCVVZ7KZ1e0flfwwNLBRJ0E0YCI=/0x0:2880x1620/960x540/media/img/mt/2025/09/2025_09_09_school_ai/original.jpg)
  
  Illustration by Ben Kothe / The Atlantic. Sources: 3drenderings / Getty; shorrocks / Getty.
  
  September 11, 2025, 7:30 AM ET
- Since the release of ChatGPT, in 2022, colleges and universities have been engaged in an experiment to discover whether artificially intelligent chatbots and the liberal-arts tradition can coexist. Notwithstanding a few [exceptions](https://www.theatlantic.com/ideas/archive/2024/10/chatgpt-vs-university-honor-code/680336/), by now the answer is clear: They cannot. AI-enabled cheating is pretty much everywhere. As a May _New York_ magazine essay [put it](https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html?isNewSocialUser=false&providerId=google.com), “students at large state schools, the Ivies, liberal-arts schools in New England, universities abroad, professional schools, and community colleges are relying on AI to ease their way through every facet of their education.”
  
  This rampant, unauthorized AI use degrades the educational experience of individual students who overly rely on the technology _and_ [those who wish to avoid using it](https://www.theatlantic.com/technology/archive/2025/09/high-school-student-ai-education/684088/). When students ask ChatGPT to write papers, complete problem sets, or formulate discussion queries, they rob themselves of the opportunity to learn how to think, study, and answer complex questions. These students also undermine their non-AI-using peers. Recently, a professor friend of mine told me that several students had confessed to him that they felt their classmates’ constant AI use was ruining their own college years.
  
  Widespread AI use also subverts the institutional goals of colleges and universities. Large language models routinely fabricate information, and even when they do create factually accurate work, they frequently depend on intellectual-property theft. So when an educational institution as a whole produces large amounts of AI-generated scholarship, it fails to create new ideas and add to the storehouse of human wisdom. AI also takes a prodigious ecological toll and relies on [labor exploitation](https://time.com/6247678/openai-chatgpt-kenya-workers/), which is impossible to square with many colleges’ and universities’ professed commitment to protecting the environment and fighting economic inequality.
- Some schools have nonetheless responded to the AI crisis by waving the white flag: The Ohio State University [recently pledged](https://www.nbc4i.com/news/local-news/ohio-state-university/ohio-state-announces-every-student-will-use-ai-in-class/) that students in every major will learn to use AI so they can become “bilingual” in the tech; the California State University system, which has nearly half a million students, [said](https://www.nytimes.com/2025/06/07/technology/chatgpt-openai-colleges.html) it aims to be “the nation’s first and largest A.I.-empowered university system.”
- Teaching students how to use AI tools in fields where they are genuinely necessary is one thing. But infusing the college experience with the technology is deeply misguided. Even schools that have not bent the knee by “integrating” AI into campus life are mostly failing to come up with workable answers to the various problems presented by AI. At too many colleges, leaders have been reluctant to impose strict rules or harsh penalties for chatbot use, passing the buck to professors to come up with their own policies.
  
  In [a recent cri de coeur](https://thepointmag.com/examined-life/a-matter-of-words/), Megan Fritts, a philosophy professor at the University of Arkansas at Little Rock, detailed how her own institution has not articulated clear, campus-wide guidance on AI use. She argued that if the humanities are to survive, “universities will need to embrace a much more radical response to AI than has so far been contemplated.” She called for these classrooms to ban large language models, which she described as “tools for offloading the task of genuine expression,” then went a step further, saying that their use should be _shunned_, “seen as a faux pas of the deeply different norms of a deeply different space.”
  
  [Read: ChatGPT doesn’t need to ruin college](https://www.theatlantic.com/ideas/archive/2024/10/chatgpt-vs-university-honor-code/680336/)
- Yet to my mind, the “radical” policy Fritts proposes—which _is_ radical, when you consider how many universities are encouraging their students to use AI—is not nearly radical enough. Shunning AI use in classrooms is a good start, but schools need to think bigger than that. All institutions of higher education in the United States should be animated by the same basic question: What are the most effective things—even if they sound extreme—that we can do to limit, and ideally abolish, the unathorized use of AI on campus? Once the schools have an answer, their leaders should do everything in their power to make these things happen.
  
  The answers will be different for different kinds of schools, rich or poor, public or private, big or small. At the type of place where I taught until recently—a small, selective, private liberal-arts college—administrators can go quite far in limiting AI use, if they have the guts to do so. They should commit to a ruthless de-teching not just of classrooms but of their entire institution. Get rid of Wi-Fi and return to Ethernet, which would allow schools greater control over where and when students use digital technologies. To that end, [smartphones](https://www.theatlantic.com/family/archive/2025/08/phone-ban-school-parents/683982/) and laptops should also be banned on campus. If students want to type notes in class or papers in the library, they can use [digital typewriters](https://www.theatlantic.com/technology/archive/2016/05/freewrite/481566/), which have word processing but nothing else. Work and research requiring students to use the internet or a computer can take place in designated labs. This lab-based computer work can and should include learning to use AI, a technology that is likely here to stay and about which ignorance represents neither wisdom nor virtue.
- These measures may sound draconian but they are necessary to make the barrier to cheating prohibitively high. Tech bans would also benefit campus intellectual culture and social life. This is something that many undergraduates seem to recognize themselves, as antitech [“Luddite clubs”](https://www.nytimes.com/2025/01/30/style/luddite-teens-reunion.html) with slogans promising human connection sprout up at colleges around the country, and [the ranks](https://www.theguardian.com/society/2024/apr/27/the-boring-phone-stressed-out-gen-z-ditch-smartphones-for-dumbphones) of students carrying [flip phones](https://www.bu.edu/articles/2025/ditched-smartphone-for-flip-phone/) grow. Nixing screens for everyone on campus, and not just those who self-select into antitech organizations, could change campus communities for the better—we’ve already seen the [transformative impact](https://www.theguardian.com/lifeandstyle/2024/jan/17/cellphone-smartphone-bans-schools) of initiatives like these at the high-school level. My hope is that the quad could once again be a place where students (and faculty) talk to one another, rather than one where everyone walks zombified about the green with their nose down and their eyes on their devices.
  
  Colleges that are especially committed to maintaining this tech-free environment could require students to live on campus, so they can’t use AI tools at home undetected. Many schools, including those with a high number of students who have children or other familial responsibilities, might not be able to do this. But some could, and they should. (And they should of course provide whatever financial aid is necessary to enable students to live in the dorms.)
  
  Restrictions also must be applied without exceptions, even for students with disabilities or learning differences. I realize this may be a controversial position to take, but if done right, a full tech ban can benefit everyone. Although laptops and AI transcription services can be helpful for students with special needs, they are rarely essential. Instead of allowing a disability exception, colleges with tech bans should provide peer tutors, teaching assistants, and writing centers to help students who require extra assistance—low-tech strategies that decades of pedagogical research show to be effective in making education more accessible. This support may be more expensive than a tech product, but it would give students the tools they really need to succeed academically. The idea that the only way to create an inclusive classroom is through gadgets and software is little more than ed-tech-industry propaganda. Investing in _human_ specialists, however, would be good for students of all abilities. Last year I visited my undergraduate alma mater, Haverford College, which has a well-staffed writing center, and one student said something that’s stuck with me: “The writing center is more useful than ChatGPT anyway. If I need help, I go there.”
- Another reason that a no-exceptions policy is important: If students with disabilities are permitted to use laptops and AI, a significant percentage of other students will most likely find a way to get the same allowances, rendering the ban useless. I witnessed this time and again when I was a professor—students without disabilities finding ways to use disability accommodations for their own benefit. Professors I know who are still in the classroom have told me that this remains a serious problem.
  
  [Read: AI cheating is getting worse](https://www.theatlantic.com/technology/archive/2024/08/another-year-ai-college-cheating/679502/)
  
  Universities with tens of thousands of students might have trouble enforcing a campus smartphone-and-laptop ban, and might not have the capacity to require everyone to live on campus. But they can still take meaningful steps toward creating a culture that prioritizes learning and creativity, and that cultivates the attention spans necessary for sustained intellectual engagement. Schools that don’t already have an honor code can develop one. They can require students to sign a pledge vowing not to engage in unauthorized AI use, and levy consequences, including expulsion, for those who don’t comply. They can ban websites such as ChatGPT from their campus networks. Where possible, they can offer more small, discussion-based courses. And they can require students to write essays in class, proctored by professors and teaching assistants, and to take end-of-semester written tests or oral exams that require extensive knowledge of course readings. Many professors are already [taking these steps](https://www.wsj.com/business/chatgpt-ai-cheating-college-blue-books-5e3014a6?gaa_at=eafs&gaa_n=ASWzDAjPmizoDL1hu17qmnOM1MrjOgnBmWVu8nr6xgeIMMCSpDZHYumEHRdoDluXXAQ%3D&gaa_ts=68b88cbb&gaa_sig=WpvHUsiiYrjy6Llx8mBi-UwJEjKuUF3Bx8voBC8tgukfHad57EIVjLfZz803OtFt1K-pvvTk5hUxgcx-qRA_hw%3D%3D) themselves, but few schools have adopted such policies institution-wide.
  
  Some will object that limiting AI use so aggressively will not prepare students for the “real world,” where large language models seem omnipresent. But colleges have never mimicked the real world, which is why so many people romanticize them. Undergraduate institutions have long promised America’s young people opportunities to learn in cloistered conditions that are deliberately curated, anachronistic, and unrepresentative of work and life outside the quad. Why should that change? Indeed, one imagines that plenty of students (and parents) might eagerly apply to institutions offering an alternative to the AI-dominated college education offered elsewhere. If this turns out not to be true—if America does not have enough students interested in reading, writing, and learning on their own to fill its colleges and universities—then society has a far bigger problem on its hands, and one might reasonably ask why all of these institutions continue to exist.
  
  Taking drastic measures against AI in higher education is not about embracing Luddism, which is generally a losing proposition. It is about creating the conditions necessary for young people to learn to read, write, and think, which is to say, the conditions necessary for modern civilization to continue to reproduce itself. Institutions of higher learning can abandon their centuries-long educational project. Or they can resist.